import OpenAI from 'openai';
import { searchSimilarDocuments } from './pgClient';

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

export interface RAGResponse {
  answer: string;
  sources: Array<{
    id: string;
    score: number;
    text: string;
    chunk_preview: string;
  }>;
  responseTime: number;
  tokensUsed?: number;
}

/**
 * RAGë¥¼ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤
 * @param question ì‚¬ìš©ìì˜ ì§ˆë¬¸
 * @param maxSources ì°¸ì¡°í•  ë¬¸ì„œì˜ ìµœëŒ€ ìˆ˜
 * @returns RAG ë‹µë³€ ê²°ê³¼
 */
export async function generateRAGAnswer(question: string, maxSources: number = 3): Promise<RAGResponse> {
  const startTime = Date.now();
  
  try {
    // 1. ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
    console.log('\nğŸ” ê²€ìƒ‰ ì¿¼ë¦¬:', question);
    console.log('ğŸ“Š ìµœëŒ€ ê²€ìƒ‰ ìˆ˜:', maxSources);
    
    const searchResults = await searchSimilarDocuments(question, maxSources);
    
    console.log('\nğŸ“š ê²€ìƒ‰ê²°ê³¼ (ìƒìœ„5ê±´):');
    searchResults.slice(0, 5).forEach((result, index) => {
      console.log(`\n--- ê²°ê³¼ ${index + 1} (ê´€ë ¨ë„: ${(result.score * 100).toFixed(2)}%) ---`);
      console.log(`ID: ${result.id}`);
      console.log(`í…ìŠ¤íŠ¸: ${result.text.substring(0, 150)}...`);
    });
    
    if (searchResults.length === 0) {
      console.log('\nâŒ ê²€ìƒ‰ê²°ê³¼ ì—†ìŒ');
      return {
        answer: 'ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì§ˆë¬¸ì„ ë³€ê²½í•˜ì—¬ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.',
        sources: [],
        responseTime: Date.now() - startTime
      };
    }

    // 2. ì»¨í…ìŠ¤íŠ¸ êµ¬ì¶•
    console.log('\nğŸ“ ì»¨í…ìŠ¤íŠ¸ êµ¬ì¶•ì¤‘...');
    const context = searchResults
      .map((doc: { text: string; score: number }, index: number) => {
        const preview = doc.text.length > 100 
          ? doc.text.substring(0, 100) + '...' 
          : doc.text;
        
        return `[ì†ŒìŠ¤${index + 1}] (ê´€ë ¨ë„: ${(doc.score * 100).toFixed(1)}%)\n${doc.text}`;
      })
      .join('\n\n---\n\n');

    // 3. í”„ë¡¬í”„íŠ¸ êµ¬ì¶•
    console.log('\nğŸ¤– AI ë‹µë³€ ìƒì„± ì¤‘...');
    const systemPrompt = `ë‹¹ì‹ ì€ ì œê³µëœ ì •ë³´ì— ê¸°ë°˜í•˜ì—¬ ë‹µë³€í•˜ëŠ” ì „ë¬¸ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

ë‹¤ìŒ ê·œì¹™ì— ë”°ë¼ ë‹µë³€í•˜ì„¸ìš”:
1. ì œê³µëœ ì •ë³´ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì‚¬ìš©
2. ì œê³µëœ ì •ë³´ì— ë¶€ì¡±í•œ ê²½ìš°ì—ëŠ” ì§€ì‹ì„ ë³´ì™„ì ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ì„ ì¶©ì‹¤íˆ í•˜ì‹­ì‹œì˜¤
3. ì •ë³´ì˜ ì¶œì²˜ë¥¼ ëª…í™•íˆí•˜ì‹­ì‹œì˜¤ : 
- ì œê³µëœ ì •ë³´ë¡œë¶€í„°ì˜ ê²½ìš°ëŠ” 'ì†ŒìŠ¤ Xì— ì˜í•˜ë©´...'ë¼ê³  ëª…ê¸° 
- ë‹¹ì‹ ì˜ ì§€ì‹ìœ¼ë¡œë¶€í„°ì˜ ê²½ìš°ëŠ” 'ì¼ë°˜ì ìœ¼ë¡œ...'ë‚˜ 'ì•Œê³  ìˆëŠ” ê³³ì—ì„œëŠ”...'ë¼ê³  ëª…ê¸°
4. ì¶”ì¸¡ì´ë‚˜ ì¶”ì¸¡ì€ í”¼í•´, ì‚¬ì‹¤ì— ê·¼ê±°í•´ íšŒë‹µí•´ ì£¼ì„¸ìš”
5. ë‹µë³€ì€ ì´í•´í•˜ê¸° ì‰½ê³  êµ¬ì¡°í™”í•˜ì—¬ ì œê³µí•˜ì‹­ì‹œì˜¤.`;

    const userPrompt = `ë‹¤ìŒ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.
í•„ìš”í•œ ê²½ìš° ë‹¹ì‹ ì˜ ì§€ì‹ì„ í™œìš©í•˜ì—¬ ë‹µë³€ì„ ì™„ë²½í•˜ê²Œ í•˜ì„¸ìš”.

[ì°¸ê³  ì •ë³´]
${context}

[ì§ˆë¬¸]
${question}

[ë‹µë³€]`;

    // 4. OpenAI APIë¡œ ë‹µë³€ ìƒì„±
    const response = await openai.chat.completions.create({
      model: 'gpt-4',
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: userPrompt }
      ],
      temperature: 0.2,
      max_tokens: 1500,
    });

    const answer = response.choices[0].message.content || 'ì—ëŸ¬ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤';
    const tokensUsed = response.usage?.total_tokens;

    // 5. ì‘ë‹µì„ êµ¬ì¶•
    const sources = searchResults.map((doc: { id: string; score: number; text: string }) => ({
      id: doc.id,
      score: doc.score,
      text: doc.text,
      chunk_preview: doc.text.length > 150 
        ? doc.text.substring(0, 150) + '...' 
        : doc.text
    }));

    const responseTime = Date.now() - startTime;

    console.log('\nâœ… ë‹µë³€ ìƒì„± ì™„ë£Œ');
    console.log(`â±ï¸ ì²˜ë¦¬ ì‹œê°„: ${responseTime}ms`);
    console.log(`ğŸ“Š ì‚¬ìš© í† í° ìˆ˜: ${tokensUsed}`);
    console.log('\nğŸ“ ìƒì„±ëœ ë‹µë³€:');
    console.log(answer);

    return {
      answer,
      sources,
      responseTime,
      tokensUsed
    };

  } catch (error) {
    console.error('\nâŒ RAG ë‹µë³€ ìƒì„± ì˜¤ë¥˜:', error);
    throw new Error(`ë‹µë³€ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: ${error}`);
  }
}

/**
 * ì§ˆë¬¸ì˜ í’ˆì§ˆì„ í™•ì¸í•©ë‹ˆë‹¤
 * @param question í™•ì¸í•  ì§ˆë¬¸
 * @returns í’ˆì§ˆ í™•ì¸ ê²°ê³¼
 */
export function validateQuestion(question: string): { isValid: boolean; message?: string } {
  if (!question || question.trim().length === 0) {
    return { isValid: false, message: 'ì§ˆë¬¸ì´ ì…ë ¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤' };
  }

  if (question.trim().length < 5) {
    return { isValid: false, message: 'ì§ˆë¬¸ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤ (5ì ì´ìƒ ì…ë ¥í•´ì£¼ì„¸ìš”)' };
  }

  if (question.length > 1000) {
    return { isValid: false, message: 'ì§ˆë¬¸ì´ ë„ˆë¬´ ê¹ë‹ˆë‹¤ (1000ì ì´ë‚´ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”)' };
  }

  return { isValid: true };
}

/**
 * ê°„ë‹¨í•œ ì§ˆë¬¸ ë¶„í•´ ê¸°ëŠ¥ (ë‚˜ì¤‘ì— í™•ì¥ìš©)
 * @param question ë¶„í•´í•  ì§ˆë¬¸
 * @returns ë¶„í•´ëœ í•˜ìœ„ ì§ˆë¬¸ì˜ ë¦¬ìŠ¤íŠ¸
 */
export async function decomposeQuestion(question: string): Promise<string[]> {
  try {
    const response = await openai.chat.completions.create({
      model: 'gpt-4o',
      messages: [
        {
          role: 'system',
          content: 'ë³µì¡í•œ ì§ˆë¬¸ì„, ê²€ìƒ‰ì— ì í•©í•œ ì—¬ëŸ¬ ê°œì˜ ì‘ì€ ì¿¼ë¦¬ë¡œ ë¶„í•´í•´ì£¼ì„¸ìš”. ê° ì¿¼ë¦¬ëŠ” ë…ë¦½ì ìœ¼ë¡œ ê²€ìƒ‰ ê°€ëŠ¥í•´ì•¼ í•©ë‹ˆë‹¤.'
        },
        {
          role: 'user',
          content: `ë‹¤ìŒ ì§ˆë¬¸ì„ ê²€ìƒ‰ ì¿¼ë¦¬ë¡œ ë¶„í•´í•´ì£¼ì„¸ìš” (JSON ë°°ì—´ í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•´ì£¼ì„¸ìš”):\n${question}`
        }
      ],
      temperature: 0.1,
      response_format: { type: 'json_object' }
    });

    const result = JSON.parse(response.choices[0].message.content || '{"queries": []}');
    return result.queries || [question];
  } catch (error) {
    console.warn('ì§ˆë¬¸ ë¶„í•´ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤:', error);
    return [question]; // í´ë°±: ì›ë˜ ì§ˆë¬¸ ê·¸ëŒ€ë¡œ ì‚¬ìš©
  }
}
